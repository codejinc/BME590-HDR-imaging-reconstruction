{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, math\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "# import network, img_io\n",
    "\n",
    "eps = 1.0/255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import LDR images \n",
    "these HDR images are derived from HDR image dataset from google. \n",
    "the code used for this procedure is function from MATLAB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images():\n",
    "    # read data from <data> folder\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = # simulated LDR images 152, 1208, 768, 3\n",
    "y = # ground truth HDR images, 152, 4208 3120 3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the images \n",
    "Convert the images into smaples??? or just image before the filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. create input pipeline for generating training/testing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be either X_train/y_train or X_test/y_test, so we make a placeholder that we can feed into:\n",
    "X_train_or_test = tf.placeholder(tf.float32, [None, 1028, 768, 3], name='input_LDR')\n",
    "y_train_or_test = tf.placeholder(tf.float32, [None, 4208, 3120, 3], name='ground_truth_HDR')\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "# create a tf dataset, from which we can generate batches\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_or_test, y_train_or_test))\n",
    "dataset = dataset.batch(batch_size).repeat(None)\n",
    "\n",
    "batch_generator = dataset.make_initializable_iterator()\n",
    "X_batch, y_batch = batch_generator.get_next()  # batches symbolically generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. create three pixel-level filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filters = True\n",
    "\n",
    "input_filters = tf.Variable(np.ones([1028, 768, 3]), dtype=tf.float32, trainable=train_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. generate the filtered images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = tf.multiply(X_batch, input_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. propagate back to the image plane: filtered LDR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add noise:\n",
    "image = X_filtered + tf.random.normal([1028, 768, 3], mean=0, stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. process the filtered image through a Physical CNN to optimize filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Pass through Digital layer to get HDR output image.\n",
    "- ### use the same loss as the Digital layer. \n",
    "loss is illumination + reflectance loss\n",
    "I just need revise the hdrcnn_predict.py into a function, which return the HDR image and the loss?\n",
    "\n",
    "revise get_final to return not only the HDR imgae, but also the cost. \n",
    "\n",
    "or should I define my own loss? \n",
    "\n",
    "FLAGS.sep_loss is the flag to separate loss into illumination and reflectance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "tf.flags.DEFINE_float(\"num_epochs\",         \"100.0\",   \"Number of training epochs\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\",      \"0.00005\", \"Starting learning rate for Adam optimizer\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\",       \"4\",       \"Batch size for training\")\n",
    "\n",
    "tf.flags.DEFINE_float(\"train_size\",         \"0.99\",    \"Fraction of data to use for training, the rest is validation data\")\n",
    "\n",
    "tf.flags.DEFINE_bool(\"sep_loss\",            \"true\",    \"Use illumination + reflectance loss\")\n",
    "tf.flags.DEFINE_float(\"lambda_ir\",          \"0.5\",     \"Reflectance weight for the ill+refl loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x, y_):\n",
    "    \"\"\"\n",
    "    params required to calculate loss:\n",
    "    y_\n",
    "    x\n",
    "    eps\n",
    "    FLAGS.sep_loss\n",
    "    FLAGS.lambda_ir\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Loss separated into illumination and reflectance terms\n",
    "    if FLAGS.sep_loss:\n",
    "        y_log_ = tf.log(y_+eps)  \n",
    "        x_log = tf.log(tf.pow(x, 2.0)+eps)\n",
    "\n",
    "        # Luminance\n",
    "        lum_kernel = np.zeros((1, 1, 3, 1))\n",
    "        lum_kernel[:, :, 0, 0] = 0.213\n",
    "        lum_kernel[:, :, 1, 0] = 0.715\n",
    "        lum_kernel[:, :, 2, 0] = 0.072\n",
    "        y_lum_lin_ = tf.nn.conv2d(y_, lum_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        y_lum_lin = tf.nn.conv2d(tf.exp(y)-eps, lum_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        x_lum_lin = tf.nn.conv2d(x, lum_kernel, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Log luminance\n",
    "        y_lum_ = tf.log(y_lum_lin_ + eps)\n",
    "        y_lum = tf.log(y_lum_lin + eps)\n",
    "        x_lum = tf.log(x_lum_lin + eps)\n",
    "\n",
    "        # Gaussian kernel\n",
    "        nsig = 2\n",
    "        filter_size = 13\n",
    "        interval = (2*nsig+1.)/(filter_size)\n",
    "        ll = np.linspace(-nsig-interval/2., nsig+interval/2., filter_size+1)\n",
    "        kern1d = np.diff(st.norm.cdf(ll))\n",
    "        kernel = kernel_raw/kernel_raw.sum()\n",
    "\n",
    "        # Illumination, approximated by means of Gaussian filtering\n",
    "        weights_g = np.zeros((filter_size, filter_size, 1, 1))\n",
    "        weights_g[:, :, 0, 0] = kernel\n",
    "        y_ill_ = tf.nn.conv2d(y_lum_, weights_g, [1, 1, 1, 1], padding='SAME')\n",
    "        y_ill = tf.nn.conv2d(y_lum, weights_g, [1, 1, 1, 1], padding='SAME')\n",
    "        x_ill = tf.nn.conv2d(x_lum, weights_g, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Reflectance\n",
    "        y_refl_ = y_log_ - tf.tile(y_ill_, [1,1,1,3])\n",
    "        y_refl = y - tf.tile(y_ill, [1,1,1,3])\n",
    "        x_refl = x - tf.tile(x_ill, [1,1,1,3])\n",
    "\n",
    "        cost =              tf.reduce_mean( ( FLAGS.lambda_ir*tf.square( tf.subtract(y_ill, y_ill_) ) + (1.0-FLAGS.lambda_ir)*tf.square( tf.subtract(y_refl, y_refl_) ) )*msk )\n",
    "        cost_input_output = tf.reduce_mean( ( FLAGS.lambda_ir*tf.square( tf.subtract(x_ill, y_ill_) ) + (1.0-FLAGS.lambda_ir)*tf.square( tf.subtract(x_refl, y_refl_) ) )*msk )\n",
    "    else:\n",
    "        cost =              tf.reduce_mean( tf.square( tf.subtract(y, tf.log(y_+eps) )*msk ) )\n",
    "        cost_input_output = tf.reduce_mean( tf.square( tf.subtract(tf.log(y_+eps), tf.log(tf.pow(x, 2.0)+eps) )*msk ) );\n",
    "    return [cost, cost_input_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = calculate_loss(x=image, y_=y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=Flags.learning_rate).minimize(loss)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(batch):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(batch[i])\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code tells our batch_generator to generate training batches:\n",
    "sess.run(batch_generator.initializer, feed_dict={X_train_or_test: X_train, y_train_or_test: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(image.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    _, loss_i = sess.run([train_op, loss])\n",
    "    if i%1000 == 0:\n",
    "        print(loss_i)\n",
    "        print(input_filters.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot examples after the training\n",
    "plot_examples(image.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results():\n",
    "    \"\"\"plot:\n",
    "    simulated_LDR\n",
    "    simulated_HDR AFTER training\n",
    "    simulated_HDR BEFORE training    \n",
    "    ground_truth_HDR\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
